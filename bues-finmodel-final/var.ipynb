{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Estimates of Value-at-Risk for shares of a Bucharest Stock Exchange-traded company, 2015-2019\n",
    "\n",
    "**Author:** Nicholas VJ Alexander\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install nbconvert\n",
    "!pip -q install ipython\n",
    "!pip -q install yfinance\n",
    "!pip -q install matplotlib\n",
    "!pip -q install cryptography\n",
    "import requests, getpass, base64, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from IPython.display import Markdown as md\n",
    "from datetime import datetime\n",
    "from scipy.stats import norm, t\n",
    "from cryptography.fernet import Fernet\n",
    "from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "from cryptography.hazmat.primitives import hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Most recently updated:** 2024-01-20 17:48 UTC"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "currtime = datetime.now().strftime('%Y-%m-%d %H:%M UTC')\n",
    "md(f\"**Most recently updated:** {currtime}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Contact:** https://www.linkedin.com/in/nvalexander\n",
    "\n",
    "---\n",
    "\n",
    "**Abstract:**\n",
    "\n",
    "This working paper tests several methods of estimation for Value-at-Risk (VaR), comparing their performance with the actual findings over the subsequent 12 months.\n",
    "\n",
    "---\n",
    "\n",
    "**Disclaimer:**\n",
    "\n",
    "This file is work in progress. As long as this disclaimer is included, its results are not to be assumed as correct.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The European Union is at the forefront of global banking reforms aimed at mitigating risks in the private banking system. Additionally, the core objective of the European Banking Authority is a transparent banking environment. To these goals, Directive 2013/36/EU of the European Parliament and of the Council, and its implementation, Commission Implementing Regulation (eu) 2019/912, require adherence to Basel III rules across the EU member states. The latter's Annex 4 requires Credit Institutions disclose, every year, \"Own funds requirements for market risk\" using \"standardized methods\".\n",
    "\n",
    "The strictness of these regulations is merely a faÃ§ade. The current Basel framework approach, in the section \"MAR33. Internal models approach: capital requirements calculation\", states that \"supervisors may permit banks to use models based on either historical simulation, Monte Carlo simulation, or other appropriate analytical methods\". Hence, in this working paper, I will test several methods for estimating Value-at-Risk (VaR) in a hypothetical portfolio comprising a single type of equity, namely a company traded on the Bucharest Stock Exchange.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "Closing values for the interval 2015-2019 are obtained through a HTTP scraper written by the author. As it not clear whether scraping bvb.ro data is in agreement with its rules, I protected a trivial section of the scraper with a password in the code posted on Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_from_password(password: str, salt: bytes):\n",
    "    kdf = PBKDF2HMAC(\n",
    "        algorithm=hashes.SHA256(),\n",
    "        length=32,\n",
    "        salt=base64.urlsafe_b64decode(salt),\n",
    "        iterations=100000,\n",
    "        backend=default_backend()\n",
    "    )\n",
    "    key = base64.urlsafe_b64encode(kdf.derive(password.encode()))\n",
    "    return key\n",
    "\n",
    "def decrypt_message(encrypted_message, password, salt):\n",
    "    key = key_from_password(password, salt)\n",
    "    fernet = Fernet(key)\n",
    "    try:\n",
    "        decrypted_message = fernet.decrypt(encrypted_message.encode()).decode()\n",
    "        return decrypted_message\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def fetch_bvb_data(ticker, startdate, enddate):\n",
    "    start_timestamp = int(datetime.strptime(startdate, '%Y-%m-%d').timestamp())\n",
    "    end_timestamp = int(datetime.strptime(enddate, '%Y-%m-%d').timestamp())\n",
    "    url = f'https://wapi.bvb.ro/api/history?symbol={ticker}&dt=DAILY&p=day&ajust=0&from={start_timestamp}&to={end_timestamp}'\n",
    "    referrer_url = decrypt_message(\n",
    "        'gAAAAABlq-CfDvJGetCCbdadT9aEdRwD9AjQNL9CcYh8aINR_uiBOOrD_58SDsTN9pO0IE4twO2ohut3SMEHpFRSfskGWv6N048H3y1yKQWWhyb-kpFPuLhFA6UkkTvLcKduTBwxXFG4m8LeP-RPkYcxi9TrHjX3uTkrFcBKIyA54XtgWcMvLr22XDeMaWLCg2bN85W5UadJ', \n",
    "        password,\n",
    "        'RYGlNyoOQupNEt4l0f8IdQ=='\n",
    "        )\n",
    "    if not referrer_url:\n",
    "        print(\"Incorrect password, cannot decrypt the URL.\")\n",
    "        return pd.DataFrame()\n",
    "    headers = {'Referer': referrer_url}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    del referrer_url\n",
    "    del headers\n",
    "    if response.status_code != 200:\n",
    "        return pd.DataFrame()  # Return an empty DataFrame in case of unsuccessful response\n",
    "    data = response.json()\n",
    "    if data.get('s') != 'ok':\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if status is not 'ok'\n",
    "    return pd.DataFrame({\n",
    "        'Date': [datetime.utcfromtimestamp(ts).strftime('%Y-%m-%d') for ts in data['t']],\n",
    "        'Open': data['o'],\n",
    "        'High': data['h'],\n",
    "        'Low': data['l'],\n",
    "        'Close': data['c'],\n",
    "        'Volume': data['v']\n",
    "    })\n",
    "\n",
    "password = getpass.getpass(\"Enter your BVB fetcher password: \")\n",
    "ticker = 'EL'\n",
    "startdate = '2016-01-01'\n",
    "enddate = '2021-01-01'\n",
    "df = fetch_bvb_data(ticker, startdate, enddate)\n",
    "#print(df)\n",
    "\n",
    "del password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VaR (Historical Simulation): -0.01904761904761898\n",
      "ES (Historical Simulation): -0.030985270396360773\n",
      "VaR (Normal Distribution): -0.02109922627245241\n",
      "ES (Normal Distribution): 0.02600319014511007\n",
      "VaR (t-Distribution): -0.018319758488147077\n",
      "ES (t-Distribution): 0.8544695687918541\n"
     ]
    }
   ],
   "source": [
    "df['DateTime'] = pd.to_datetime(df['Date'])\n",
    "df = df.sort_values(by='DateTime')\n",
    "df['Daily_Return'] = df['Close'].pct_change()\n",
    "\n",
    "train_data = df[(df['DateTime'] >= '2015-01-01') & (df['DateTime'] < '2019-01-01')]['Daily_Return'].dropna()\n",
    "test_data = df[df['DateTime'] >= '2019-01-01']['Daily_Return'].dropna()\n",
    "\n",
    "confidence_level = 0.95\n",
    "\n",
    "# Historical Simulation method\n",
    "VaR_HS = np.percentile(train_data, (1 - confidence_level) * 100)\n",
    "ES_HS = train_data[train_data <= VaR_HS].mean()\n",
    "\n",
    "# Normal Distribution method\n",
    "mean_return, std_dev = norm.fit(train_data)\n",
    "VaR_Normal = norm.ppf(1 - confidence_level, mean_return, std_dev)\n",
    "ES_Normal = mean_return + std_dev * norm.pdf(norm.ppf(1 - confidence_level)) / (1 - confidence_level)\n",
    "\n",
    "# t-Distribution method\n",
    "degrees_of_freedom, loc, scale = t.fit(train_data)\n",
    "VaR_t = t.ppf(1 - confidence_level, degrees_of_freedom, loc, scale)\n",
    "ES_t = (degrees_of_freedom / (degrees_of_freedom - 1) * loc + scale * t.pdf(t.ppf(1 - confidence_level, degrees_of_freedom, loc, scale), degrees_of_freedom, loc, scale) / (1 - confidence_level)) if degrees_of_freedom > 1 else np.nan\n",
    "\n",
    "# Output the results\n",
    "print(f\"VaR (Historical Simulation): {VaR_HS}\")\n",
    "print(f\"ES (Historical Simulation): {ES_HS}\")\n",
    "print(f\"VaR (Normal Distribution): {VaR_Normal}\")\n",
    "print(f\"ES (Normal Distribution): {ES_Normal}\")\n",
    "print(f\"VaR (t-Distribution): {VaR_t}\")\n",
    "print(f\"ES (t-Distribution): {ES_t}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Exceedances: 36\n",
      "Expected Exceedances: 24.900000000000023\n"
     ]
    }
   ],
   "source": [
    "exceedances = test_data[test_data < VaR_HS].count()\n",
    "expected_exceedances = len(test_data) * (1 - confidence_level)\n",
    "print(f\"Observed Exceedances: {exceedances}\")\n",
    "print(f\"Expected Exceedances: {expected_exceedances}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
